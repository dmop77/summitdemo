Sure â€” hereâ€™s the complete Markdown file as a single copy-ready document you can paste directly into your repo.

â¸»


# ğŸ§  LiveKit Voice Agent Enhancement Plan

## Overview
This document outlines the plan to extend the existing **LiveKit voice agent** system by integrating:
1. A **web scraping and Supabase ingestion pipeline**.  
2. An **enhanced conversational workflow** that includes a Pulpo-based scheduling flow with rescheduling logic.  
3. A **verification layer using the Archon MCP server** (located inside Claudeâ€™s codebase) to validate agent behavior and LiveKit documentation references.

The objective is to allow a user to input a website link, automatically scrape it, store embeddings in Supabase, and enable the voice agent to:
- Discuss the scraped content intelligently.  
- Greet the user using Cartesia voice (English).  
- Collect user info (name, email, website link).  
- Create and **reschedule** appointments through Pulpo.  

> âš ï¸ **Note:**  
> The base `.env` configuration already exists.  
> We will only **extend it** with additional keys for Supabase and web scraping â€” not create a new `.env.example` file.

---

## ğŸ§© System Components

### 1. LiveKit Voice Agent (Existing)
- **Already functional.**
- Uses:
  - **STT:** Deepgram  
  - **LLM:** OpenAI  
  - **TTS:** Cartesia  
- Fully capable of conversation flow and Pulpo API calls.

### 2. Web Scraping and Supabase Integration (New)
- The user inputs a **website link**.  
- A **Python scraper** fetches key text content and produces a **short summary + embedding**.  
- The embedding is stored in **Supabase**, linked to the userâ€™s record (email, name, URL).

#### Workflow:
1. User provides `name`, `email`, and `link` through the frontend form.  
2. Backend runs the Python scraper and creates an embedding using the existing OpenAI model.  
3. Store results in Supabase table:
   ```sql
   Table: scraped_links
   Columns:
     - id (uuid)
     - user_name (text)
     - user_email (text)
     - url (text)
     - summary (text)
     - embedding (vector)
     - created_at (timestamp)

	4.	The embedding is later retrieved when the voice agent interacts with the user.

âš ï¸ Note:
Supabase and the web scraping module are not yet integrated.
This step will add both functionalities on top of the existing backend.

â¸»

ğŸ—£ï¸ Voice Interaction Flow

Agent Goals:
	1.	Greet the user in English using Cartesia (friendly + concise tone).
	2.	Reference scraped topic: Briefly summarize the subject from the embedded content.
	3.	Schedule a call via Pulpo using userâ€™s email and name.
	4.	Showcase rescheduling logic:
	â€¢	Reject the first proposed appointment (simulate unavailability).
	â€¢	Check available times via Pulpo.
	â€¢	Offer a second available slot and confirm it.

Example Flow:

Agent: Hi {name}, I just read the page you shared about {topic_summary}.
Agent: It looks interesting â€” Iâ€™d love to discuss it with you. Letâ€™s find a time for a quick call.

(User chooses a time)

Agent: Looks like that time isnâ€™t available. Let me check other options.
Agent: How about {alternative_time}? Should I book that for you?

(User confirms)

Agent: Great! Iâ€™ve scheduled your call in Pulpo and added your notes about {topic_summary}.


â¸»

ğŸ§  Archon MCP Verification
	â€¢	The Archon MCP server is not inside this repository â€” it is part of Claudeâ€™s code environment.
	â€¢	It should be used to:
	1.	Review LiveKit documentation to ensure the agent correctly handles session flow, transcription, and streaming.
	2.	Verify that Pulpo API calls are made correctly and that rescheduling logic works as expected.
	3.	Optionally cross-check any future integrations (e.g., Supabase SDK usage, web scraping setup).

âœ… Goal: The Archon MCP acts as an intelligent reviewer to confirm that LiveKit and Pulpo integrations align with best practices and current documentation.

â¸»

âš™ï¸ Environment Variables

Add the following keys on top of the existing .env file â€” do not replace it.

# Supabase
SUPABASE_URL=<your_supabase_project_url>
SUPABASE_KEY=<your_supabase_api_key>

# Web Scraper
SCRAPER_ENDPOINT=<local_or_remote_scraper_url>

The rest of your .env (LiveKit, OpenAI, Deepgram, Cartesia, Pulpo, etc.) remains unchanged.

â¸»

ğŸ§± Reusability Setup

To make the project portable and shareable:
	â€¢	Ensure environment variables are loaded from .env â€” no hardcoded credentials.
	â€¢	Database credentials (Supabase) can be shared with trusted collaborators.
	â€¢	The system should run locally or remotely with the same flow:
	1.	User inputs data (name, email, link).
	2.	Scraper runs â†’ Supabase updated.
	3.	Voice agent engages â†’ Pulpo scheduling occurs.
	4.	Archon MCP verifies documentation and consistency.

â¸»

ğŸ§© Architecture Overview

        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚        User          â”‚
        â”‚ (name, email, link)  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚  Web Scraper   â”‚
          â”‚ (Python script)â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚   Supabase DB  â”‚
          â”‚ embeddings +   â”‚
          â”‚ summaries      â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚  LiveKit Agent â”‚
          â”‚ Deepgram STT   â”‚
          â”‚ OpenAI LLM     â”‚
          â”‚ Cartesia TTS   â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚    Pulpo API   â”‚
          â”‚ Appointment &  â”‚
          â”‚ Rescheduling   â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 



â¸»

âœ… Next Steps
	1.	Integrate Supabase with schema described above.
	2.	Connect the web scraping Python script to the backend ingestion pipeline.
	3.	Test the voice agent flow end-to-end with Pulpo scheduling and rescheduling logic.
	4.	Run Archon MCP validation on LiveKit + Pulpo interaction flow.
	5.	Ensure the final system runs locally and can be cloned by another user with minimal config updates.

â¸»

ğŸ§¾ Summary

Component	Status	Description
LiveKit Agent	âœ… Existing	Uses Deepgram (STT), OpenAI (LLM), Cartesia (TTS)
Pulpo Integration	âœ… Existing	Will now include rescheduling demo
Web Scraper	âš™ï¸ New	Scrapes page + creates summary + embedding
Supabase	âš™ï¸ New	Stores scraped data and embeddings
Archon MCP	ğŸ” External	Used for verifying LiveKit and integration consistency
.env	ğŸ”§ Extend Only	Add Supabase + Scraper keys; do not replace existing


