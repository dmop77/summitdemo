<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Task Voice Agent - OpenAI Realtime</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            overflow: hidden;
        }

        .container {
            text-align: center;
            color: white;
            max-width: 600px;
            width: 90%;
        }

        h1 {
            font-size: 2.5rem;
            margin-bottom: 1rem;
            font-weight: 600;
        }

        .subtitle {
            font-size: 1.1rem;
            margin-bottom: 3rem;
            opacity: 0.9;
        }

        .orb-container {
            position: relative;
            width: 300px;
            height: 300px;
            margin: 0 auto 3rem;
        }

        .orb {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            width: 200px;
            height: 200px;
            border-radius: 50%;
            background: radial-gradient(circle at 30% 30%, rgba(255, 255, 255, 0.8), rgba(255, 255, 255, 0.1));
            box-shadow: 0 0 60px rgba(255, 255, 255, 0.4),
                        0 0 100px rgba(255, 255, 255, 0.2),
                        inset 0 0 40px rgba(255, 255, 255, 0.2);
            animation: float 4s ease-in-out infinite;
            transition: all 0.3s ease;
        }

        .orb.speaking {
            animation: pulse 0.8s ease-in-out infinite, float 4s ease-in-out infinite;
            box-shadow: 0 0 80px rgba(255, 255, 255, 0.6),
                        0 0 140px rgba(255, 255, 255, 0.4),
                        inset 0 0 60px rgba(255, 255, 255, 0.3);
        }

        .orb.listening {
            background: radial-gradient(circle at 30% 30%, rgba(100, 255, 150, 0.8), rgba(100, 255, 150, 0.1));
            box-shadow: 0 0 60px rgba(100, 255, 150, 0.5),
                        0 0 100px rgba(100, 255, 150, 0.3);
            animation: glow 1.5s ease-in-out infinite, float 4s ease-in-out infinite;
        }

        .orb.connecting {
            background: radial-gradient(circle at 30% 30%, rgba(255, 193, 7, 0.8), rgba(255, 193, 7, 0.1));
            box-shadow: 0 0 60px rgba(255, 193, 7, 0.5),
                        0 0 100px rgba(255, 193, 7, 0.3);
            animation: pulse 1s ease-in-out infinite, float 4s ease-in-out infinite;
        }

        .ripple {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            width: 200px;
            height: 200px;
            border-radius: 50%;
            border: 2px solid rgba(255, 255, 255, 0.5);
            opacity: 0;
        }

        .orb.speaking .ripple {
            animation: ripple 1.5s ease-out infinite;
        }

        .orb.listening .ripple {
            border-color: rgba(100, 255, 150, 0.5);
            animation: ripple 1.5s ease-out infinite;
        }

        @keyframes float {
            0%, 100% { transform: translate(-50%, -50%) translateY(0px); }
            50% { transform: translate(-50%, -50%) translateY(-20px); }
        }

        @keyframes pulse {
            0%, 100% { transform: translate(-50%, -50%) scale(1); }
            50% { transform: translate(-50%, -50%) scale(1.1); }
        }

        @keyframes glow {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.7; }
        }

        @keyframes ripple {
            0% {
                width: 200px;
                height: 200px;
                opacity: 0.6;
            }
            100% {
                width: 350px;
                height: 350px;
                opacity: 0;
            }
        }

        .status {
            font-size: 1.2rem;
            margin-bottom: 1rem;
            min-height: 30px;
            font-weight: 500;
        }

        .controls {
            display: flex;
            gap: 1rem;
            justify-content: center;
            margin-top: 2rem;
        }

        button {
            padding: 1rem 2rem;
            font-size: 1rem;
            border: 2px solid white;
            background: rgba(255, 255, 255, 0.1);
            color: white;
            border-radius: 50px;
            cursor: pointer;
            transition: all 0.3s ease;
            backdrop-filter: blur(10px);
            font-weight: 600;
        }

        button:hover {
            background: rgba(255, 255, 255, 0.2);
            transform: translateY(-2px);
            box-shadow: 0 5px 20px rgba(0, 0, 0, 0.2);
        }

        button:active {
            transform: translateY(0);
        }

        button:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }

        button.primary {
            background: rgba(255, 255, 255, 0.3);
        }

        .transcript-box {
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
            border-radius: 20px;
            padding: 1.5rem;
            margin-top: 2rem;
            max-height: 200px;
            overflow-y: auto;
            text-align: left;
            border: 1px solid rgba(255, 255, 255, 0.2);
        }

        .transcript-item {
            margin-bottom: 1rem;
            line-height: 1.6;
        }

        .transcript-user {
            color: #a7f3d0;
            font-weight: 600;
        }

        .transcript-agent {
            color: #fbbf24;
            font-weight: 600;
        }

        .error-message {
            background: rgba(239, 68, 68, 0.2);
            border: 1px solid rgba(239, 68, 68, 0.5);
            border-radius: 10px;
            padding: 1rem;
            margin-top: 1rem;
            color: #fecaca;
        }

        .info-message {
            background: rgba(59, 130, 246, 0.2);
            border: 1px solid rgba(59, 130, 246, 0.5);
            border-radius: 10px;
            padding: 1rem;
            margin-top: 1rem;
            color: #bfdbfe;
        }

        @media (max-width: 768px) {
            h1 { font-size: 2rem; }
            .orb-container { width: 250px; height: 250px; }
            .orb { width: 150px; height: 150px; }
            .controls { flex-direction: column; }
            button { width: 100%; }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Task Voice Agent</h1>
        <p class="subtitle">Speak to create tasks naturally with OpenAI Realtime API</p>

        <div class="orb-container">
            <div class="orb" id="orb">
                <div class="ripple"></div>
                <div class="ripple" style="animation-delay: 0.5s;"></div>
                <div class="ripple" style="animation-delay: 1s;"></div>
            </div>
        </div>

        <div class="status" id="status">Click "Connect" to start</div>

        <div class="controls">
            <button id="connectBtn" class="primary">Connect</button>
            <button id="disconnectBtn" disabled>Disconnect</button>
        </div>

        <div class="transcript-box" id="transcriptBox" style="display: none;">
            <div id="transcript"></div>
        </div>
    </div>

    <script>
        const orb = document.getElementById('orb');
        const status = document.getElementById('status');
        const connectBtn = document.getElementById('connectBtn');
        const disconnectBtn = document.getElementById('disconnectBtn');
        const transcriptBox = document.getElementById('transcriptBox');
        const transcript = document.getElementById('transcript');

        let realtimeWs = null;
        let isConnected = false;
        let audioContext = null;
        let microphone = null;
        let audioStream = null;
        let audioQueue = [];
        let isPlaying = false;
        let nextPlaybackTime = 0;

        // Configuration - get ephemeral key from your server
        const AUTH_SERVER_URL = 'http://localhost:8082';

        function updateOrbState(state) {
            orb.classList.remove('speaking', 'listening', 'connecting');
            if (state === 'speaking') {
                orb.classList.add('speaking');
            } else if (state === 'listening') {
                orb.classList.add('listening');
            } else if (state === 'connecting') {
                orb.classList.add('connecting');
            }
        }

        function updateStatus(message) {
            status.textContent = message;
        }

        function addTranscript(type, text) {
            transcriptBox.style.display = 'block';
            const item = document.createElement('div');
            item.className = 'transcript-item';
            const label = document.createElement('span');
            label.className = type === 'user' ? 'transcript-user' : 'transcript-agent';
            label.textContent = type === 'user' ? 'You: ' : 'Agent: ';
            item.appendChild(label);
            item.appendChild(document.createTextNode(text));
            transcript.appendChild(item);
            transcriptBox.scrollTop = transcriptBox.scrollHeight;
        }

        function showError(message) {
            const errorDiv = document.createElement('div');
            errorDiv.className = 'error-message';
            errorDiv.textContent = message;
            document.querySelector('.container').appendChild(errorDiv);
            setTimeout(() => errorDiv.remove(), 5000);
        }

        function showInfo(message) {
            const infoDiv = document.createElement('div');
            infoDiv.className = 'info-message';
            infoDiv.textContent = message;
            document.querySelector('.container').appendChild(infoDiv);
            setTimeout(() => infoDiv.remove(), 5000);
        }

        async function getEphemeralKey() {
            try {
                const response = await fetch(`${AUTH_SERVER_URL}/session`, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' }
                });
                
                if (!response.ok) {
                    throw new Error(`HTTP ${response.status}: ${response.statusText}`);
                }
                
                const data = await response.json();
                return data.client_secret.value;
            } catch (error) {
                console.error('Failed to get ephemeral key:', error);
                throw new Error(`Failed to get ephemeral key: ${error.message}`);
            }
        }

        async function setupAudio() {
            try {
                audioContext = new AudioContext({ sampleRate: 24000 });
                
                // Resume audio context if suspended (required by modern browsers)
                if (audioContext.state === 'suspended') {
                    await audioContext.resume();
                }
                
                console.log('Audio context state:', audioContext.state);
                console.log('Audio context sample rate:', audioContext.sampleRate);
                
                audioStream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        sampleRate: 24000,
                        channelCount: 1,
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true
                    } 
                });
                
                microphone = audioContext.createMediaStreamSource(audioStream);
                
                // Create audio worklet for processing
                await audioContext.audioWorklet.addModule(`data:text/javascript,
                    class AudioProcessor extends AudioWorkletProcessor {
                        process(inputs, outputs, parameters) {
                            const input = inputs[0];
                            if (input && input.length > 0) {
                                const channelData = input[0];
                                const pcm16 = new Int16Array(channelData.length);
                                for (let i = 0; i < channelData.length; i++) {
                                    const s = Math.max(-1, Math.min(1, channelData[i]));
                                    pcm16[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
                                }
                                this.port.postMessage(pcm16.buffer);
                            }
                            return true;
                        }
                    }
                    registerProcessor('audio-processor', AudioProcessor);
                `);
                
                const processorNode = new AudioWorkletNode(audioContext, 'audio-processor');
                processorNode.port.onmessage = (event) => {
                    if (realtimeWs && realtimeWs.readyState === WebSocket.OPEN) {
                        const base64Audio = btoa(String.fromCharCode(...new Uint8Array(event.data)));
                        realtimeWs.send(JSON.stringify({
                            type: 'input_audio_buffer.append',
                            audio: base64Audio
                        }));
                    }
                };
                
                microphone.connect(processorNode);
                
                return true;
            } catch (error) {
                console.error('Error setting up audio:', error);
                throw new Error(`Failed to setup audio: ${error.message}`);
            }
        }

        function JSON_dumps(obj) {
            return JSON.stringify(obj);
        }

        function playAudioChunk(base64Audio) {
            try {
                console.log('Playing audio chunk, base64 length:', base64Audio.length);
                
                // Decode base64 to binary
                const binaryString = atob(base64Audio);
                const len = binaryString.length;
                const bytes = new Uint8Array(len);
                for (let i = 0; i < len; i++) {
                    bytes[i] = binaryString.charCodeAt(i);
                }
                
                // Convert PCM16 to Float32 for Web Audio API
                const pcm16 = new Int16Array(bytes.buffer);
                const float32 = new Float32Array(pcm16.length);
                for (let i = 0; i < pcm16.length; i++) {
                    float32[i] = pcm16[i] / 32768.0;
                }
                
                console.log('Audio buffer size:', float32.length, 'samples');
                
                // Create audio buffer and play
                const audioBuffer = audioContext.createBuffer(1, float32.length, 24000);
                audioBuffer.getChannelData(0).set(float32);
                
                const source = audioContext.createBufferSource();
                source.buffer = audioBuffer;
                source.connect(audioContext.destination);
                
                // Schedule playback to maintain continuity
                const currentTime = audioContext.currentTime;
                if (nextPlaybackTime < currentTime) {
                    nextPlaybackTime = currentTime;
                }
                source.start(nextPlaybackTime);
                nextPlaybackTime += audioBuffer.duration;
                
                console.log('Audio scheduled to play at:', nextPlaybackTime - audioBuffer.duration);
                return true;
            } catch (error) {
                console.error('Error playing audio chunk:', error);
                return false;
            }
        }

        async function connect() {
            try {
                updateStatus('Getting session token...');
                updateOrbState('connecting');
                
                const ephemeralKey = await getEphemeralKey();
                
                updateStatus('Connecting to OpenAI Realtime API...');
                
                const url = `wss://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview-2024-10-01`;
                realtimeWs = new WebSocket(url, ['realtime', `openai-insecure-api-key.${ephemeralKey}`, 'openai-beta.realtime-v1']);
                
                realtimeWs.onopen = async () => {
                    console.log('Connected to OpenAI Realtime API');
                    updateStatus('Setting up audio...');
                    
                    // Setup audio
                    await setupAudio();
                    
                    // Send session configuration
                    realtimeWs.send(JSON_dumps({
                        type: 'session.update',
                        session: {
                            modalities: ['text', 'audio'],
                            instructions: `You are a professional task management assistant for Pulpoo, helping users create tasks efficiently through voice conversation.

YOUR ROLE:
- ALWAYS greet the user first when they connect - don't wait for them to speak
- Capture task information through natural, friendly conversation
- Ask clarifying questions when details are unclear or missing
- Confirm all details before creating the task
- Be concise but thorough

TASK INFORMATION TO COLLECT:
REQUIRED: Title (clear, descriptive task title)
OPTIONAL: Description, Deadline (specific date/time), Importance (LOW, MEDIUM, HIGH - defaults to HIGH)

IMPORTANT:
- All tasks assigned to cuevas@pulpoo.com automatically
- Default deadline: 24 hours from now
- Default importance: HIGH

Keep responses natural and conversational. Be professional but approachable.`,
                            voice: 'alloy',
                            input_audio_format: 'pcm16',
                            output_audio_format: 'pcm16',
                            input_audio_transcription: { model: 'whisper-1' },
                            turn_detection: {
                                type: 'server_vad',
                                threshold: 0.5,
                                prefix_padding_ms: 300,
                                silence_duration_ms: 500
                            },
                            temperature: 0.8
                        }
                    }));
                    
                    // Send initial greeting after session is configured
                    setTimeout(() => {
                        if (realtimeWs && realtimeWs.readyState === WebSocket.OPEN) {
                            // Add a conversation item with the greeting
                            realtimeWs.send(JSON.stringify({
                                type: 'conversation.item.create',
                                item: {
                                    type: 'message',
                                    role: 'assistant',
                                    content: [{
                                        type: 'text',
                                        text: 'Hello! I\'m your Pulpoo task management assistant. I\'m here to help you create tasks quickly and efficiently. What would you like to create a task for today?'
                                    }]
                                }
                            }));
                            
                            // Trigger the assistant to speak the greeting
                            realtimeWs.send(JSON.stringify({
                                type: 'response.create'
                            }));
                        }
                    }, 1000);
                    
                    isConnected = true;
                    updateStatus('Connected - Agent will greet you...');
                    updateOrbState('speaking');
                    connectBtn.disabled = true;
                    disconnectBtn.disabled = false;
                    
                    showInfo('Voice agent is ready! The assistant will greet you first.');
                };
                
                realtimeWs.onmessage = (event) => {
                    try {
                        const data = JSON.parse(event.data);
                        console.log('OpenAI event:', data.type);
                        
                        if (data.type === 'session.created') {
                            console.log('Session created:', data.session.id);
                        } else if (data.type === 'conversation.item.input_audio_transcription.completed') {
                            addTranscript('user', data.transcript);
                        } else if (data.type === 'response.audio.delta') {
                            updateOrbState('speaking');
                            updateStatus('Speaking...');
                            console.log('Received audio delta, length:', data.delta ? data.delta.length : 0);
                            // Play audio response
                            if (data.delta) {
                                const success = playAudioChunk(data.delta);
                                if (!success) {
                                    console.error('Failed to play audio chunk');
                                }
                            }
                        } else if (data.type === 'response.audio.done') {
                            updateOrbState('listening');
                            updateStatus('Listening...');
                            nextPlaybackTime = 0; // Reset for next response
                            console.log('Audio response completed');
                        } else if (data.type === 'response.text.delta') {
                            // Update agent transcript incrementally
                        } else if (data.type === 'response.text.done') {
                            addTranscript('agent', data.text);
                        } else if (data.type === 'error') {
                            console.error('Realtime API error:', data.error);
                            showError(data.error.message || 'An error occurred');
                        }
                    } catch (error) {
                        console.error('Error parsing message:', error);
                    }
                };
                
                realtimeWs.onerror = (error) => {
                    console.error('WebSocket error:', error);
                    showError('Connection error occurred');
                };
                
                realtimeWs.onclose = () => {
                    console.log('Disconnected from OpenAI Realtime API');
                    isConnected = false;
                    updateStatus('Disconnected');
                    updateOrbState('idle');
                    connectBtn.disabled = false;
                    disconnectBtn.disabled = true;
                    
                    if (audioContext) {
                        audioContext.close();
                        audioContext = null;
                    }
                    if (audioStream) {
                        audioStream.getTracks().forEach(track => track.stop());
                        audioStream = null;
                    }
                    
                    // Reset audio playback state
                    audioQueue = [];
                    isPlaying = false;
                    nextPlaybackTime = 0;
                };
                
            } catch (error) {
                console.error('Connection error:', error);
                updateStatus('Connection failed');
                updateOrbState('idle');
                showError(error.message);
                connectBtn.disabled = false;
            }
        }

        function disconnect() {
            if (realtimeWs) {
                realtimeWs.close();
                realtimeWs = null;
            }
            
            if (audioContext) {
                audioContext.close();
                audioContext = null;
            }
            
            if (audioStream) {
                audioStream.getTracks().forEach(track => track.stop());
                audioStream = null;
            }
            
            // Reset audio playback state
            audioQueue = [];
            isPlaying = false;
            nextPlaybackTime = 0;
            
            updateStatus('Disconnected');
            updateOrbState('idle');
            connectBtn.disabled = false;
            disconnectBtn.disabled = true;
        }

        // Event listeners
        connectBtn.addEventListener('click', connect);
        disconnectBtn.addEventListener('click', disconnect);

        // Handle page unload
        window.addEventListener('beforeunload', () => {
            if (isConnected) {
                disconnect();
            }
        });

        // Check browser support
        if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
            showError('Your browser does not support audio recording. Please use a modern browser.');
            connectBtn.disabled = true;
        }

        if (!window.WebSocket) {
            showError('Your browser does not support WebSockets. Please use a modern browser.');
            connectBtn.disabled = true;
        }

        if (!window.AudioContext && !window.webkitAudioContext) {
            showError('Your browser does not support Web Audio API. Please use a modern browser.');
            connectBtn.disabled = true;
        }
    </script>
</body>
</html>